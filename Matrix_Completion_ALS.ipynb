{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCsXFavbwEws",
        "outputId": "88cb91d6-3150-4e59-ed8a-1e7c9c458e69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "metadata": {
        "id": "zwidUAzbwNWI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset\n",
        "ratings_path = '/content/drive/My Drive/MatrixCompletion/ratings.csv'\n",
        "movies_path = '/content/drive/My Drive/MatrixCompletion/movies.csv'\n",
        "tags_path = '/content/drive/My Drive/MatrixCompletion/tags.csv'\n",
        "links_path = '/content/drive/My Drive/MatrixCompletion/links.csv'\n",
        "\n",
        "# Load the dataset\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "movies = pd.read_csv(movies_path)\n",
        "tags = pd.read_csv(tags_path)\n",
        "links = pd.read_csv(links_path)\n"
      ],
      "metadata": {
        "id": "n61HiKBkwNT3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def als_train_gd(ratings, k=10, steps=20, learning_rate=0.01, reg=0.1, max_gradient=5.0):\n",
        "    \"\"\"\n",
        "    ALS implementation using Gradient Descent for optimization with stability fixes.\n",
        "\n",
        "    Parameters:\n",
        "        ratings (ndarray): User-item ratings matrix (unobserved entries set as 0).\n",
        "        k (int): Number of latent factors.\n",
        "        steps (int): Number of iterations.\n",
        "        learning_rate (float): Initial learning rate for gradient descent.\n",
        "        reg (float): Regularization parameter.\n",
        "        max_gradient (float): Maximum threshold for gradient clipping.\n",
        "\n",
        "    Returns:\n",
        "        U (ndarray): User latent factors.\n",
        "        V (ndarray): Item latent factors.\n",
        "    \"\"\"\n",
        "    num_users, num_items = ratings.shape\n",
        "\n",
        "    # Initialize user and item latent factors with small random values\n",
        "    U = np.random.rand(num_users, k) * 0.01\n",
        "    V = np.random.rand(num_items, k) * 0.01\n",
        "\n",
        "    # Mask to identify observed ratings (non-zero entries)\n",
        "    observed_mask = ratings > 0\n",
        "\n",
        "    print(\"Training ALS with Gradient Descent...\")\n",
        "\n",
        "    for step in range(steps):\n",
        "        # Dynamic learning rate decay\n",
        "        lr = learning_rate / (1 + step * 0.1)\n",
        "\n",
        "        # Update U (user latent factors)\n",
        "        for u in range(num_users):\n",
        "            for f in range(k):\n",
        "                error_sum = 0\n",
        "                for i in range(num_items):\n",
        "                    if observed_mask[u, i]:  # Only consider observed ratings\n",
        "                        pred = np.dot(U[u, :], V[i, :])\n",
        "                        error_sum += (ratings[u, i] - pred) * (-V[i, f])\n",
        "                # Gradient update with clipping\n",
        "                error_sum = np.clip(error_sum, -max_gradient, max_gradient)\n",
        "                U[u, f] -= lr * (error_sum + reg * U[u, f])\n",
        "\n",
        "        # Update V (item latent factors)\n",
        "        for i in range(num_items):\n",
        "            for f in range(k):\n",
        "                error_sum = 0\n",
        "                for u in range(num_users):\n",
        "                    if observed_mask[u, i]:  # Only consider observed ratings\n",
        "                        pred = np.dot(U[u, :], V[i, :])\n",
        "                        error_sum += (ratings[u, i] - pred) * (-U[u, f])\n",
        "                # Gradient update with clipping\n",
        "                error_sum = np.clip(error_sum, -max_gradient, max_gradient)\n",
        "                V[i, f] -= lr * (error_sum + reg * V[i, f])\n",
        "\n",
        "        # Compute loss (for monitoring)\n",
        "        loss = 0\n",
        "        for u in range(num_users):\n",
        "            for i in range(num_items):\n",
        "                if observed_mask[u, i]:\n",
        "                    pred = np.dot(U[u, :], V[i, :])\n",
        "                    loss += (ratings[u, i] - pred) ** 2\n",
        "        loss += reg * (np.sum(U ** 2) + np.sum(V ** 2))\n",
        "\n",
        "        # Print loss and check for divergence\n",
        "        print(f\"Step: {step + 1}, Loss: {loss:.4f}\")\n",
        "        if np.isnan(loss):\n",
        "            print(\"Divergence detected! Stopping training.\")\n",
        "            break\n",
        "\n",
        "    return U, V\n",
        "\n",
        "def evaluate(reconstructed_matrix, test_matrix, test_mask):\n",
        "    \"\"\"\n",
        "    Evaluate the model using RMSE and MAE on the test set.\n",
        "\n",
        "    Parameters:\n",
        "        reconstructed_matrix (ndarray): Predicted user-item matrix.\n",
        "        test_matrix (ndarray): True ratings for the test set.\n",
        "        test_mask (ndarray): Mask for observed test ratings.\n",
        "\n",
        "    Returns:\n",
        "        rmse (float): Root Mean Squared Error.\n",
        "        mae (float): Mean Absolute Error.\n",
        "    \"\"\"\n",
        "    test_predictions = reconstructed_matrix[test_mask]\n",
        "    actual_test_ratings = test_matrix[test_mask]\n",
        "    rmse = np.sqrt(np.mean((actual_test_ratings - test_predictions) ** 2))\n",
        "    mae = np.mean(np.abs(actual_test_ratings - test_predictions))\n",
        "    return rmse, mae\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    ratings_matrix = ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0).values\n",
        "\n",
        "    # Create test mask (20% observed ratings for testing)\n",
        "    np.random.seed(42)\n",
        "    observed_mask = ratings_matrix > 0\n",
        "    test_mask = np.random.rand(*ratings_matrix.shape) < 0.2\n",
        "    train_mask = observed_mask & ~test_mask\n",
        "\n",
        "    train_matrix = np.where(train_mask, ratings_matrix, 0)\n",
        "    test_matrix = np.where(test_mask, ratings_matrix, 0)\n",
        "\n",
        "    # Train ALS model using Gradient Descent\n",
        "    k = 10  # Number of latent factors\n",
        "    steps = 100  # Number of iterations\n",
        "    learning_rate = 0.01\n",
        "    reg = 0.1\n",
        "\n",
        "    U, V = als_train_gd(train_matrix, k, steps, learning_rate, reg)\n",
        "\n",
        "    # Reconstruct the matrix\n",
        "    reconstructed_matrix = np.dot(U, V.T)\n",
        "\n",
        "    # Evaluate the model\n",
        "    print(\"\\nEvaluating ALS Model:\")\n",
        "    rmse, mae = evaluate(reconstructed_matrix, test_matrix, test_mask)\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "t8y1LBwZx1Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfc8cbc-cd17-400c-810a-cb634a872862"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ALS with Gradient Descent...\n",
            "Step: 1, Loss: 1066503.9081\n",
            "Step: 2, Loss: 1038919.2534\n",
            "Step: 3, Loss: 996506.7222\n",
            "Step: 4, Loss: 943495.8955\n",
            "Step: 5, Loss: 883396.9696\n",
            "Step: 6, Loss: 819017.2821\n",
            "Step: 7, Loss: 752575.1942\n",
            "Step: 8, Loss: 685812.1577\n",
            "Step: 9, Loss: 620091.9672\n",
            "Step: 10, Loss: 556477.2633\n",
            "Step: 11, Loss: 495790.5625\n",
            "Step: 12, Loss: 438664.9641\n",
            "Step: 13, Loss: 385582.3337\n",
            "Step: 14, Loss: 336902.7841\n",
            "Step: 15, Loss: 292884.9567\n",
            "Step: 16, Loss: 253702.0928\n",
            "Step: 17, Loss: 219438.0540\n",
            "Step: 18, Loss: 190092.3446\n",
            "Step: 19, Loss: 165515.0000\n",
            "Step: 20, Loss: 145490.9033\n",
            "Step: 21, Loss: 129614.1455\n",
            "Step: 22, Loss: 117311.2784\n",
            "Step: 23, Loss: 108048.8288\n",
            "Step: 24, Loss: 101178.2036\n",
            "Step: 25, Loss: 96074.1025\n",
            "Step: 26, Loss: 92223.5744\n",
            "Step: 27, Loss: 89239.7822\n",
            "Step: 28, Loss: 86842.3661\n",
            "Step: 29, Loss: 84803.0970\n",
            "Step: 30, Loss: 83014.8701\n",
            "Step: 31, Loss: 81420.4804\n",
            "Step: 32, Loss: 79984.4651\n",
            "Step: 33, Loss: 78678.8013\n",
            "Step: 34, Loss: 77483.2859\n",
            "Step: 35, Loss: 76382.5333\n",
            "Step: 36, Loss: 75365.0249\n",
            "Step: 37, Loss: 74421.3900\n",
            "Step: 38, Loss: 73543.4764\n",
            "Step: 39, Loss: 72724.4773\n",
            "Step: 40, Loss: 71958.7987\n",
            "Step: 41, Loss: 71240.9602\n",
            "Step: 42, Loss: 70565.6058\n",
            "Step: 43, Loss: 69928.7985\n",
            "Step: 44, Loss: 69327.1437\n",
            "Step: 45, Loss: 68757.5994\n",
            "Step: 46, Loss: 68217.5616\n",
            "Step: 47, Loss: 67704.5496\n",
            "Step: 48, Loss: 67216.3625\n",
            "Step: 49, Loss: 66750.9217\n",
            "Step: 50, Loss: 66306.4433\n",
            "\n",
            "Evaluating ALS Model:\n",
            "RMSE: 2.5294\n",
            "MAE: 2.2170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_users, num_items = ratings.shape\n",
        "\n",
        "# Initialize user and item latent factors randomly\n",
        "U = np.random.rand(num_users, k)\n",
        "V = np.random.rand(num_items, k)\n",
        "\n",
        "# Mask to identify observed ratings (non-zero entries)\n",
        "observed_mask = ratings > 0"
      ],
      "metadata": {
        "id": "NbdLt-Eu50op"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(observed_mask))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfa0vK4K53WQ",
        "outputId": "bc16332c-7e6f-4f96-e805-e94f647d7d26"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PyXFkWQs6Dsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}