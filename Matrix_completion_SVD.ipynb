{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9pgDD85lpgc",
        "outputId": "d3e701b4-a2b2-4613-adca-4e067bda3676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "ERcaoy9qlxbO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the dataset\n",
        "ratings_path = '/content/drive/My Drive/MatrixCompletion/ratings.csv'\n",
        "movies_path = '/content/drive/My Drive/MatrixCompletion/movies.csv'\n",
        "tags_path = '/content/drive/My Drive/MatrixCompletion/tags.csv'\n",
        "links_path = '/content/drive/My Drive/MatrixCompletion/links.csv'\n",
        "\n",
        "# Load the dataset\n",
        "ratings = pd.read_csv(ratings_path)\n",
        "movies = pd.read_csv(movies_path)\n",
        "tags = pd.read_csv(tags_path)\n",
        "links = pd.read_csv(links_path)\n"
      ],
      "metadata": {
        "id": "n-SvCFGrlxXw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_matrix = ratings.pivot(index='userId', columns='movieId', values='rating')"
      ],
      "metadata": {
        "id": "U9LACDR7n4Nz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------------------------\n",
        "# 1. Data Preparation\n",
        "# ----------------------------\n",
        "def prepare_data(matrix, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Splits the observed entries into train and test sets.\n",
        "    Replaces missing entries with 0 for initial processing.\n",
        "    \"\"\"\n",
        "    observed_mask = ~np.isnan(matrix)\n",
        "    train_mask = observed_mask & (np.random.rand(*matrix.shape) > test_size)\n",
        "    test_mask = observed_mask & ~train_mask\n",
        "\n",
        "    train_matrix = np.where(train_mask, matrix, 0)\n",
        "    test_matrix = np.where(test_mask, matrix, 0)\n",
        "\n",
        "    #print(\"Number of test values:\", np.sum(test_mask))\n",
        "\n",
        "\n",
        "    return train_matrix, test_matrix, train_mask, test_mask\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Gradient Descent SVD\n",
        "# ----------------------------\n",
        "def gradient_descent_svd(train_matrix, k, lr, reg, steps):\n",
        "    \"\"\"\n",
        "    Performs gradient descent optimization to approximate SVD.\n",
        "    Args:\n",
        "        train_matrix: The input matrix with missing values filled as 0.\n",
        "        k: Number of latent factors.\n",
        "        lr: Learning rate for gradient descent.\n",
        "        reg: Regularization parameter.\n",
        "        steps: Number of iterations.\n",
        "\n",
        "    Returns:\n",
        "        U: User latent factor matrix.\n",
        "        V: Item latent factor matrix.\n",
        "        reconstructed: Reconstructed matrix.\n",
        "    \"\"\"\n",
        "    num_users, num_items = train_matrix.shape\n",
        "\n",
        "    # Initialize user and item matrices with small random values\n",
        "    U = np.random.normal(0, 0.1, (num_users, k))\n",
        "    V = np.random.normal(0, 0.1, (num_items, k))\n",
        "\n",
        "    # Gradient Descent Loop\n",
        "    for step in range(steps):\n",
        "        for i in range(num_users):\n",
        "            for j in range(num_items):\n",
        "                if train_matrix[i, j] > 0:  # Only observed ratings contribute to the update\n",
        "                    error_ij = train_matrix[i, j] - np.dot(U[i, :], V[j, :].T)\n",
        "\n",
        "                    # Update user and item matrices with regularization\n",
        "                    U[i, :] += lr * (error_ij * V[j, :] - reg * U[i, :])\n",
        "                    V[j, :] += lr * (error_ij * U[i, :] - reg * V[j, :])\n",
        "\n",
        "        # Compute Loss (optional for debugging)\n",
        "        if step % 10 == 0:  # Log every 10 steps\n",
        "            loss = 0\n",
        "            for i in range(num_users):\n",
        "                for j in range(num_items):\n",
        "                    if train_matrix[i, j] > 0:\n",
        "                        loss += (train_matrix[i, j] - np.dot(U[i, :], V[j, :].T))**2\n",
        "            loss += reg * (np.sum(U**2) + np.sum(V**2))\n",
        "            print(f\"Step: {step}, Loss: {loss:.4f}\")\n",
        "\n",
        "    reconstructed = np.dot(U, V.T)  # Final reconstruction\n",
        "    return U, V, reconstructed\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Evaluation\n",
        "# ----------------------------\n",
        "def evaluate(reconstructed_matrix, test_matrix, test_mask):\n",
        "    test_predictions = reconstructed_matrix[test_mask]\n",
        "    actual_test_ratings = test_matrix[test_mask]\n",
        "\n",
        "    # Check for empty arrays\n",
        "    if len(actual_test_ratings) == 0 or len(test_predictions) == 0:\n",
        "        print(\"Error: No test ratings to evaluate. Check test_mask!\")\n",
        "        return\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(actual_test_ratings, test_predictions))\n",
        "    mae = mean_absolute_error(actual_test_ratings, test_predictions)\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Main Workflow\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulated Input Matrix (Example with NaN entries)\n",
        "\n",
        "    ratings_matrix = ratings.pivot(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "    # Prepare Data\n",
        "    train_matrix, test_matrix, train_mask, test_mask = prepare_data(ratings_matrix)\n",
        "\n",
        "    # SVD with Gradient Descent\n",
        "    k = 10           # Number of latent factors\n",
        "    lr = 0.01       # Learning rate\n",
        "    reg = 0.1       # Regularization\n",
        "    steps = 100     # Number of iterations\n",
        "\n",
        "    print(\"\\nTraining Gradient Descent-based SVD...\")\n",
        "    U, V, reconstructed_matrix = gradient_descent_svd(train_matrix, k, lr, reg, steps)\n",
        "\n",
        "    # Clip predictions to valid range (1-5 in this example)\n",
        "    reconstructed_matrix = np.clip(reconstructed_matrix, 1, 5)\n",
        "\n",
        "    # Evaluate Results\n",
        "    evaluate(reconstructed_matrix, test_matrix, test_mask)\n",
        "\n",
        "    # Final Reconstructed Matrix\n",
        "    print(\"\\nReconstructed Matrix:\")\n",
        "    print(np.round(reconstructed_matrix, 2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmisCYoEzPcQ",
        "outputId": "9a36021f-d3ab-457e-fb13-71d4cfbc3780"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Gradient Descent-based SVD...\n",
            "Step: 0, Loss: 780457.8718\n",
            "Step: 10, Loss: 66516.8333\n",
            "Step: 20, Loss: 53502.5233\n",
            "Step: 30, Loss: 46551.2108\n",
            "Step: 40, Loss: 42125.9379\n",
            "Step: 50, Loss: 39249.1105\n",
            "Step: 60, Loss: 37331.3461\n",
            "Step: 70, Loss: 36013.7555\n",
            "Step: 80, Loss: 35077.3118\n",
            "Step: 90, Loss: 34389.8195\n",
            "RMSE: 0.9849\n",
            "MAE: 0.7333\n",
            "\n",
            "Reconstructed Matrix:\n",
            "[[4.75 4.27 3.85 ... 3.63 3.52 4.23]\n",
            " [3.89 3.43 3.15 ... 2.81 2.82 3.27]\n",
            " [1.34 1.85 1.63 ... 1.28 1.19 1.46]\n",
            " ...\n",
            " [3.52 3.12 2.71 ... 3.29 3.42 4.03]\n",
            " [3.53 3.22 3.1  ... 2.59 2.43 3.14]\n",
            " [4.11 3.61 3.37 ... 3.26 3.2  3.91]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1V_3cpkNzPVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrGADe3czPSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7VAaZWUWzPPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_e4P1QJzPLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvANxY1MzPIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}